I"`<h1 id="背景">背景</h1>
<ul>
  <li>尽管可视化问答发展显著，但VQA的鲁棒性不足。</li>
  <li>通过引入新的数据集和评估方式，证明当前最好的VQA模型对语言的变化的效果是脆弱的。</li>
  <li>VQA发展：LSTM+CNN，attention networks，module networks，relational networks，multimodal fusion。</li>
  <li>发现VQA领域缺乏量化测量鲁棒性的基准。</li>
</ul>

<h1 id="效果">效果</h1>

<p>『之前的VQA模型，鲁棒性展示：同一语义，回答结果不同』
<img src="/imgs/deep_learning/paper/paper-Cycle-Consistency-for-Robust-Visual-Question-Answering/2.png" alt="show robust" /></p>

<p>『采用CycleGAN后，鲁棒性展示』
<img src="/imgs/deep_learning/paper/paper-Cycle-Consistency-for-Robust-Visual-Question-Answering/3.png" alt="show robust" /></p>

<h1 id="贡献">贡献</h1>

<ul>
  <li><strong>提出循环一致性（cycle-consistent）训练方式，使VQA模型应对语言变化更具鲁棒性</strong>。</li>
  <li>提出评估VQA模型鲁棒性的方法。</li>
  <li>提供新的数据集。（VQA-Rephrasings）</li>
  <li>验证使用这种训练方法下，最先进的模型表现。</li>
</ul>

<h1 id="网络">网络</h1>

<p><img src="/imgs/deep_learning/paper/paper-Cycle-Consistency-for-Robust-Visual-Question-Answering/1.png" alt="net" /></p>

<h1 id="思路">思路</h1>

<p>网络原理基本同Cycle GAN。</p>

<h2 id="过程">过程</h2>
<ul>
  <li>数据集问题$Q$，通过F:VQA模型生成回答$A^{\prime}$。</li>
  <li>使用生成的回答$A^{\prime}$，通过G:VQG模型生成问题$Q^{\prime}$。</li>
  <li>使用生成的问题$Q^{\prime}$，通过F:VQA模型生成回答$A^{\prime \prime}$。（与前面的F是同一个VQA模型）</li>
</ul>

<h2 id="损失函数">损失函数</h2>
<ul>
  <li>对比 原问题$Q$ 和 生成的问题$Q^{\prime}$，计算损失（Question Consistency Loss）。</li>
  <li>对比 从原始问题得到回答的$A^{\prime}$ 和 数据标签$A$，计算损失（VQA Loss）。</li>
  <li>对比 数据标签$A$ 和 从生成的问题$Q^{\prime}$得到的回答$A^{\prime \prime}$，计算损失（Answer Consistency Loss）。</li>
</ul>

<script type="math/tex; mode=display">\begin{aligned}
\mathcal{L}_{\text {total}}=\mathcal{L}_{F}\left(A, A^{\prime}\right)+\lambda_{G} \mathcal{L}_{G}\left(Q, Q^{\prime}\right) \\
+\lambda_{C} \mathcal{L}_{\text {cycle}}\left(A, A^{\prime \prime}\right)
\end{aligned}</script>

<blockquote>
  <p>$\lambda$各个损失项的系数。</p>
</blockquote>

<h1 id="细节">细节</h1>

<h2 id="门机制-gating-mechanism">门机制 (Gating Mechanism)</h2>
<p>并非所有生成的问题都与I-Q-A一致，为此，作者提出一种门控机制，过滤掉一些不合适的问题。对于生成的问题$Q^{\prime}$，只保留答案与原答案的余弦相似性阈值大于$T_{sim}$的问题。(文中设$T_{sim}=0.9$)</p>

<h2 id="后期激活-late-activation">后期激活 (Late Activation)</h2>
<p>cycle-consistent关键的环节是防止模式坍塌（mode collapse）现象。为了确保各个子网络之间正常工作，作者通过在训练的最后阶段激活循环一致来解决。</p>

<h2 id="其它">其它</h2>
<h3 id="vqa改写数据集">VQA改写数据集</h3>
<p>VQA模型要在同一个问题的不同改述之间保持一致，对所有改述的答案应该相同。使用CS(K)一致性评分来衡量。（其实就是简单计算改写问题有几个生成的答案一致的比例）</p>

<script type="math/tex; mode=display">C S(k)=\sum_{Q^{\prime} \subset Q,\left|Q^{\prime}\right|=k} \frac{\mathcal{S}\left(Q^{\prime}\right)}{^{n} C_{k}}</script>

<script type="math/tex; mode=display">% <![CDATA[
\mathcal{S}\left(Q^{\prime}\right)=\left\{\begin{array}{ll}
{1} & {\text { if } \forall q \in Q^{\prime} \theta(q)>0} \\
{0} & {\text { otherwise }}
\end{array}\right. %]]></script>

<blockquote>
  <ul>
    <li>问题集合Q有n个改写，选取其中k个。C是n里去k个的组合数量。</li>
    <li>$\theta$是VQA的准确性。</li>
  </ul>
</blockquote>

<h1 id="more">more</h1>
<h2 id="note">note</h2>
<p>这是一篇2019CVPR facebook的论文，将用于图像风格迁移的Cycle GAN应用到了VQA领域，实则是将其作为一种在线数据增强的手段，来达到其鲁棒性。</p>

<h2 id="ref">ref</h2>
<ul>
  <li>理解：https://blog.csdn.net/xiasli123/article/details/102887043</li>
</ul>
:ET